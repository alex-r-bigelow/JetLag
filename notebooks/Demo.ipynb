{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a toy function that we wish to analyze in Phylanx\n",
    "def fib(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n-1)+fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_local import run_local\n",
    "job = run_local(fib,(10,),localities=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait()\n",
    "job.viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannon(size):\n",
    "    array1 = random_d([size, size], find_here(), num_localities())\n",
    "    array2 = random_d([size, size], find_here(), num_localities())\n",
    "    cannon_product_d(array1, array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the job locally. Not that canon needs 4 localties to run correctly.\n",
    "job = run_local(cannon,(120,),localities=4)\n",
    "\n",
    "# Wait for the job to finish\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the job in traveler\n",
    "job.viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the perf data from the job as a tarball\n",
    "job.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we run the function locally and collect performance data\n",
    "from visualizeInTraveler import visualizeInTraveler\n",
    "from phylanx import Phylanx\n",
    "\n",
    "# If OTF2 data is already present, we need to delete it or\n",
    "# move it out of the way before we run our function\n",
    "!rm -fr OTF2_archive\n",
    "\n",
    "# Generate a Phylanx version of the function, tell it to\n",
    "# collect performance data\n",
    "pfib = Phylanx(fib,performance='x')\n",
    "\n",
    "# Run the function\n",
    "pfib(11)\n",
    "\n",
    "# Visualize the performance data\n",
    "visualizeInTraveler(pfib,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wish to run remotely using Tapis/Agave, we\n",
    "# need to load the JetLag interface.\n",
    "from jetlag_setup import uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remote_run import remote_run, to_string, viz\n",
    "from jetlag import Universal, RemoteJobWatcher\n",
    "from knownsystems import *\n",
    "import sys\n",
    "from random import randint\n",
    "from gui_fun import gui_fun, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a random argument for our fib function\n",
    "fibno = randint(10,15)\n",
    "print('fib(',fibno,')=...',sep='',flush=True)\n",
    "\n",
    "# Submit the function to run remotely\n",
    "job = remote_run(uv, fib, (fibno,), queue='queue', nodes=1, ppn=1)\n",
    "\n",
    "# Optionally wait for the result\n",
    "job.wait()\n",
    "\n",
    "# If the result is ready, fetch it\n",
    "print(\"result:\",job.get_result())\n",
    "\n",
    "# Visualize the result\n",
    "viz(job, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can look at data from an old job if you supply the full job id\n",
    "# job = RemoteJobWatcher(uv, \"699cf0f8-0cb6-4f6a-a215-16c14c7522d4-007\")\n",
    "# print(\"result:\",job.get_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"http://localhost:8000/static/interface.html\" style='width: 100%; height: 300px;'></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO https://raw.githubusercontent.com/STEllAR-GROUP/phylanx/master/examples/algorithms/datasets/breast_cancer.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lra_demo(x, y, alpha, iterations, enable_output):\n",
    "    weights = np.zeros(np.shape(x)[1])\n",
    "    transx = np.transpose(x)\n",
    "    pred = np.zeros(np.shape(x)[0])\n",
    "    error = np.zeros(np.shape(x)[0])\n",
    "    gradientx = np.zeros(np.shape(x)[1])\n",
    "    step = 0\n",
    "    while step < iterations:\n",
    "        if (enable_output):\n",
    "            print(\"step: \", step, \", \", weights)\n",
    "        pred = 1.0 / (1.0 + np.exp(-np.dot(x, weights)))\n",
    "        error = pred - y\n",
    "        gradientx = np.dot(transx, error)\n",
    "        weights = weights - (alpha * gradientx)\n",
    "        step += 1\n",
    "    return weights\n",
    "\n",
    "file_name = \"breast_cancer.csv\"\n",
    "\n",
    "data = np.genfromtxt(file_name, skip_header=1, delimiter=\",\")\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "y = np.reshape(y, (y.shape[0], ))\n",
    "#res = lra(x, y, 1e-5, 750, 0)\n",
    "\n",
    "print(\"args:\",(x, y, 1e-5, 750, 0))\n",
    "\n",
    "job = remote_run(uv, lra_demo, (x, y, 1e-5, 750, 0), queue='fork', nodes=1, ppn=1)\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"result:\",job.get_result())\n",
    "viz(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ALS(ratings, regularization, num_factors, iterations, alpha, enable_output):\n",
    "    num_users = np.shape(ratings)[0]\n",
    "    num_items = np.shape(ratings)[1]\n",
    "\n",
    "    conf = alpha * ratings\n",
    "    conf_u = np.zeros((num_items, 1))\n",
    "    conf_i = np.zeros((num_items, 1))\n",
    "\n",
    "    c_u = np.zeros((num_items, num_items))\n",
    "    c_i = np.zeros((num_users, num_users))\n",
    "    p_u = np.zeros((num_items, 1))\n",
    "    p_i = np.zeros((num_users, 1))\n",
    "\n",
    "    I_f = np.identity(num_factors)\n",
    "    I_i = np.identity(num_items)\n",
    "    I_u = np.identity(num_users)\n",
    "\n",
    "    set_seed(0)  # noqa: F821\n",
    "    X = random([num_users, num_factors])  # noqa: F821\n",
    "    Y = random([num_items, num_factors])  # noqa: F821\n",
    "\n",
    "    i = 0\n",
    "    u = 0\n",
    "    k = 0\n",
    "\n",
    "    XtX = np.zeros((num_factors, num_factors))\n",
    "    YtY = np.zeros((num_factors, num_factors))\n",
    "    A = np.zeros([num_factors, num_factors])\n",
    "    b = np.zeros([num_factors])\n",
    "    while k < iterations:\n",
    "        if enable_output:\n",
    "            print(\"iteration \", k)\n",
    "            print(\"X: \", X)\n",
    "            print(\"Y: \", Y)\n",
    "        YtY = np.dot(np.transpose(Y), Y) + regularization * I_f\n",
    "        XtX = np.dot(np.transpose(X), X) + regularization * I_f\n",
    "        while u < num_users:\n",
    "            conf_u = conf[u, :]\n",
    "            c_u = np.diag(conf_u)\n",
    "            p_u = conf_u != 0\n",
    "            A = YtY + np.dot(np.dot(np.transpose(Y), c_u), Y)\n",
    "            b = np.dot(np.dot(np.transpose(Y), c_u + I_i), np.transpose(p_u))\n",
    "            X[u, :] = np.dot(inverse(A), b)  # noqa: F821\n",
    "            u = u + 1\n",
    "        while i < num_items:\n",
    "            conf_i = conf[:, i]\n",
    "            c_i = np.diag(conf_i)\n",
    "            p_i = conf_i != 0\n",
    "            A = XtX + np.dot(np.dot(np.transpose(X), c_i), X)\n",
    "            b = np.dot(np.dot(np.transpose(X), c_i + I_u), np.transpose(p_i))\n",
    "            Y[i, :] = np.dot(inverse(A), b)  # noqa: F821\n",
    "            i = i + 1\n",
    "        u = 0\n",
    "        i = 0\n",
    "        k = k + 1\n",
    "    return [X, Y]\n",
    "\n",
    "\n",
    "# test example\n",
    "ratings = np.zeros((10, 5))\n",
    "ratings[0, 1] = 4\n",
    "ratings[1, 0] = 1\n",
    "ratings[1, 2] = 4\n",
    "ratings[1, 4] = 5\n",
    "ratings[2, 3] = 2\n",
    "ratings[3, 1] = 8\n",
    "ratings[4, 2] = 4\n",
    "ratings[6, 4] = 2\n",
    "ratings[7, 0] = 1\n",
    "ratings[8, 3] = 5\n",
    "ratings[9, 0] = 1\n",
    "ratings[9, 3] = 2\n",
    "\n",
    "regularization = 0.1\n",
    "num_factors = 3\n",
    "iterations = 5\n",
    "alpha = 40\n",
    "enable_output = False\n",
    "\n",
    "#result = ALS(ratings, regularization, num_factors, iterations, alpha, enable_output)\n",
    "#print(\" X = \", result[0])\n",
    "#print(\" Y = \", result[1])\n",
    "job = remote_run(uv, ALS, (ratings, regularization, num_factors, iterations, alpha, enable_output), queue='fork', nodes=1, ppn=1)\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.std_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(job.err_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.get_result())\n",
    "viz(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
